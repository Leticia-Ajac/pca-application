{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_J3DghPvMzqm"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.compose import make_column_selector, ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()"
      ],
      "metadata": {
        "id": "XKygqnx1_7kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF3OxtM5Pm3j"
      },
      "outputs": [],
      "source": [
        "sample = iris.target\n",
        "\n",
        "features = pd.DataFrame(data = iris.data, columns=iris.feature_names)\n",
        "df = features.copy()\n",
        "df['sample'] = sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0tieEUiPWy3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86f429e-7598-4e33-90c5-01501cb07a37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   sepal length (cm)  150 non-null    float64\n",
            " 1   sepal width (cm)   150 non-null    float64\n",
            " 2   petal length (cm)  150 non-null    float64\n",
            " 3   petal width (cm)   150 non-null    float64\n",
            " 4   sample             150 non-null    int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 6.0 KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1UYqFvjPtOC"
      },
      "outputs": [],
      "source": [
        "pre_processador = ColumnTransformer(transformers=\n",
        "    [('standardization',StandardScaler(), make_column_selector(dtype_include=['float64']))], remainder='passthrough')\n",
        "\n",
        "features_escalonadas = pd.DataFrame(pre_processador.fit_transform(features), columns=iris.feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rStMDznN5JP"
      },
      "outputs": [],
      "source": [
        "sample_escalonado = LabelEncoder().fit_transform(sample)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F_train_model, F_test, S_train_model, S_test = train_test_split(features_escalonadas, sample_escalonado, random_state = 42,test_size = 0.30)"
      ],
      "metadata": {
        "id": "Oi0KBWAXKA-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#separando outro teste cru para passas no objeto\n",
        "F_test_model, F_test_obj, S_test_model, S_test_obj = train_test_split(F_test, S_test, random_state = 12, test_size = 0.30)"
      ],
      "metadata": {
        "id": "WKbHeJ7zGnoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA"
      ],
      "metadata": {
        "id": "uOcScPSFBOhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import time"
      ],
      "metadata": {
        "id": "HjaZG-0LDV65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_models = []\n",
        "dt_accuracies = []\n",
        "dt_times = []\n",
        "\n",
        "knn_models = []\n",
        "knn_accuracies = []\n",
        "knn_times = []\n",
        "\n",
        "nb_models = []\n",
        "nb_accuracies = []\n",
        "nb_times = []\n",
        "\n",
        "for i in range(1,len(F_train_model.columns)+1):\n",
        "  pca = PCA(n_components=i)\n",
        "  F_train_model_pca = pca.fit_transform(F_train_model)\n",
        "\n",
        "  for a in ['gini','entropy']:\n",
        "    classificador_dt_bestalpha = tree.DecisionTreeClassifier()\n",
        "\n",
        "    classificador_dt = tree.DecisionTreeClassifier(criterion=a)\n",
        "    path = classificador_dt.cost_complexity_pruning_path(F_train_model_pca, S_train_model)\n",
        "    ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
        "\n",
        "    #tirando o primeiro valor que é sempre zero\n",
        "    ccp_alphas = ccp_alphas[:-1]\n",
        "    #lista de classificadores de acordo com os alphas\n",
        "    classificadores_dt_alphas = []\n",
        "    #guardando cada classificador\n",
        "    for ccp_alpha in ccp_alphas:\n",
        "      classificador_dt_alpha = tree.DecisionTreeClassifier(ccp_alpha=ccp_alpha)\n",
        "      classificador_dt_alpha.fit(F_train_model_pca, S_train_model)\n",
        "      classificadores_dt_alphas.append(classificador_dt_alpha)\n",
        "\n",
        "    #testando cada classificador\n",
        "    acurrancy_teste = [classificador_dt_alpha.score(pca.transform(F_test_model), S_test_model) for classificador_dt_alpha in classificadores_dt_alphas]\n",
        "    #pegando a acúracia deles\n",
        "    max_accuracy_index = acurrancy_teste.index(max(acurrancy_teste))\n",
        "    #pegando a poscição do melhor classificador\n",
        "    alpha = classificadores_dt_alphas[max_accuracy_index]\n",
        "    #pegando o alpha do classificador com maior acurácia\n",
        "    best_ccp_alpha = alpha.ccp_alpha\n",
        "\n",
        "    #criando um classificador com o melhor alpha\n",
        "    classificador_dt_bestalpha = tree.DecisionTreeClassifier(criterion=a,ccp_alpha=best_ccp_alpha)\n",
        "\n",
        "\n",
        "    #definir hyperparametros sem informar o critério, pois ja esta no looping - espero que va\n",
        "    hyperparametros = {\n",
        "        'criterion': [a],\n",
        "        'splitter': ['best','random'],\n",
        "        'max_depth': [None,2,4,6,8,10,12],\n",
        "        'min_samples_split': [2,5,10],\n",
        "        'min_samples_leaf': [1,2,5,10],\n",
        "        'max_features': [None,'sqrt','log2']\n",
        "    }\n",
        "\n",
        "    #achando os melhores hyperparametros\n",
        "    grid = GridSearchCV(estimator=classificador_dt_bestalpha, param_grid=hyperparametros,scoring='accuracy')\n",
        "    #treinando\n",
        "    grid.fit(F_train_model_pca,S_train_model)\n",
        "    #pegando os melhores parametros\n",
        "    best_params = grid.best_params_\n",
        "    #olhando o melhor score\n",
        "    #print('melhor acurácia:', grid.best_score_)\n",
        "\n",
        "    #criando um novo classificador com os melhores parametros\n",
        "    classificador_dt_ccp_grid = tree.DecisionTreeClassifier(\n",
        "        criterion = best_params['criterion'],\n",
        "        max_depth = best_params['max_depth'],\n",
        "        min_samples_split = best_params['min_samples_split'],\n",
        "        min_samples_leaf = best_params['min_samples_leaf'],\n",
        "        max_features = best_params['max_features']\n",
        "    )\n",
        "    #treinando depois do grid search\n",
        "    classificador_dt_ccp_grid.fit(F_train_model_pca,S_train_model)\n",
        "\n",
        "    #nomezin\n",
        "    description = 'decisionTree_pca_' + str(i) + '_criterion_' + str(a)\n",
        "\n",
        "    #pegando a resposta do modelo e medindo o tempo\n",
        "\n",
        "    inicio = time.time()\n",
        "    answer_ccp_grid = classificador_dt_ccp_grid.predict(pca.transform(F_test_model))\n",
        "    fim = time.time()\n",
        "\n",
        "    #adicionando objeto na lista\n",
        "    dt_models.append({description: classificador_dt_ccp_grid, 'accurancy': accuracy_score(answer_ccp_grid, S_test_model), 'tempo': fim - inicio})\n",
        "    dt_accuracies.append(accuracy_score(answer_ccp_grid, S_test_model))\n",
        "    dt_times.append(fim - inicio)\n",
        "\n",
        "  #knn\n",
        "  for b in range(2,7):\n",
        "    #criando classificador\n",
        "    knn = KNeighborsClassifier()\n",
        "\n",
        "    #definindo um range de k's para fazer teste\n",
        "    params = {'n_neighbors': range(1,30)}\n",
        "\n",
        "    #fazendo a cross validation com 5 cortes\n",
        "    grid_knn = GridSearchCV(knn, params, cv=5)\n",
        "    grid_knn.fit(F_train_model_pca, S_train_model)\n",
        "\n",
        "    #pegando o resultado\n",
        "    #print(f'Melhor valor de K: {grid_knn.best_params_}')\n",
        "    #print(f'Melhor score (médio): {round(grid_knn.best_score_*100,4)}%')\n",
        "\n",
        "    #criando classificador tunado\n",
        "    knn_cv = KNeighborsClassifier()\n",
        "    knn_cv.fit(F_train_model_pca,S_train_model)\n",
        "\n",
        "    #resposta do modelo e tempo\n",
        "    inicio = time.time()\n",
        "    response_knn = knn_cv.predict(pca.transform(F_test_model))\n",
        "    fim = time.time()\n",
        "\n",
        "    #nomeandoo\n",
        "    description = 'knn_pca_' + str(i) + '_cv_' + str(b) + '_bestK_' + str(grid_knn.best_params_['n_neighbors'])\n",
        "\n",
        "    #adding\n",
        "    knn_models.append({description: knn_cv, 'accurancy': accuracy_score(response_knn, S_test_model), 'tempo': fim - inicio})\n",
        "    knn_accuracies.append(accuracy_score(response_knn, S_test_model))\n",
        "    knn_times.append(fim - inicio)\n",
        "\n",
        "  #naive bayes\n",
        "  classificador_bayes = GaussianNB()\n",
        "\n",
        "  classificador_bayes.fit(F_train_model_pca,S_train_model)\n",
        "\n",
        "  #respota e tempo\n",
        "  inicio = time.time()\n",
        "  response_nb = classificador_bayes.predict(pca.transform(F_test_model))\n",
        "  fim = time.time()\n",
        "\n",
        "  #ultimo nome obrigada deus\n",
        "  description = 'nb_pca_' + str(i)\n",
        "\n",
        "  #botando\n",
        "  nb_models.append({description: classificador_bayes, 'accurancy': accuracy_score(response_nb, S_test_model), 'tempo': fim - inicio})\n",
        "  nb_accuracies.append(accuracy_score(response_nb, S_test_model))\n",
        "  nb_times.append(fim - inicio)\n"
      ],
      "metadata": {
        "id": "ax0cvywhJZIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## melhor acurácia no melhor tempo"
      ],
      "metadata": {
        "id": "YzOG6Z2xvRHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_better_accuracie_index = []\n",
        "\n",
        "for i in range(len(dt_accuracies)):\n",
        "  if dt_accuracies[i] == max(dt_accuracies):\n",
        "    dt_better_accuracie_index.append(i)\n",
        "\n",
        "dt_better_time_index = [ dt_times[e] for e in dt_better_accuracie_index]\n",
        "\n",
        "dt_better_faster_index = dt_times.index(min(dt_better_time_index))\n",
        "dt_better_faster_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awvo0Uq9pxhb",
        "outputId": "a5d38b2a-5404-4a64-dca5-b5a2c08b6f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn_better_accuracie_index = []\n",
        "\n",
        "for i in range(len(knn_accuracies)):\n",
        "  if knn_accuracies[i] == max(knn_accuracies):\n",
        "    knn_better_accuracie_index.append(i)\n",
        "\n",
        "knn_better_time_index = [ knn_times[e] for e in knn_better_accuracie_index]\n",
        "\n",
        "knn_better_faster_index = knn_times.index(min(knn_better_time_index))\n",
        "knn_better_faster_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su-CRK-WqgtJ",
        "outputId": "2014d4b8-c473-4d68-8e3f-4f437ab1fd88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_better_accuracie_index = []\n",
        "\n",
        "for i in range(len(nb_accuracies)):\n",
        "  if nb_accuracies[i] == max(nb_accuracies):\n",
        "    nb_better_accuracie_index.append(i)\n",
        "\n",
        "nb_better_time_index = [ nb_times[e] for e in nb_better_accuracie_index]\n",
        "\n",
        "nb_better_faster_index = nb_times.index(min(nb_better_time_index))\n",
        "nb_better_faster_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXoYn2ZuqwEF",
        "outputId": "c87fb4e5-7a7d-444e-b293-222e7a95124c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pickle"
      ],
      "metadata": {
        "id": "1rtgiLstYNKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pk\n",
        "import hmac\n",
        "import hashlib"
      ],
      "metadata": {
        "id": "gE0ivoYcxOmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key = b'GodelIncompleteness'"
      ],
      "metadata": {
        "id": "daIh35GvYiKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj_serializacao = {\n",
        "    'bestModels': [dt_models[dt_better_faster_index], knn_models[knn_better_faster_index], nb_models[nb_better_faster_index]],\n",
        "    'data_test': {'f_test': F_test_obj, 's_test': S_test_obj}\n",
        "    }"
      ],
      "metadata": {
        "id": "fZ395y-BYPPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('modelo_ml.picke','wb') as doc:\n",
        "  obj_serializado = pk.dumps(obj_serializacao)\n",
        "\n",
        "  signature = hmac.new(key, obj_serializado, hashlib.sha256).digest()\n",
        "\n",
        "  data_with_signature = obj_serializado + signature\n",
        "\n",
        "  doc.write(data_with_signature)"
      ],
      "metadata": {
        "id": "5OINg8wuYd0C"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}